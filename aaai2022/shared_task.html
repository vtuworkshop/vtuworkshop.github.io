<!DOCTYPE html>
<html lang="en">
<head>
<title>Video Transcript Understanding Workshop</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<link href="layout/styles/layout.css" rel="stylesheet" type="text/css" media="all">
</head>
<body id="top">
<div class="wrapper row1">
  <header id="header" class="hoc clear">
    <!-- ################################################################################################ -->
    <div id="logo" class="fl_left">
      <h1><a href="index.html">VTU@AAAI 2022</a></h1>
    </div>
    <nav id="mainav" class="fl_right">
      <ul class="clear">
        <li><a href="index.html">Home</a></li>
        <li><a href="schedule.html">Schedule</a></li>
        <li><a href="talks.html">Invited Talks</a></li>
        <li><a href="cfp.html">CFP</a></li>
        <li class="active"><a href="shared_task.html">Shared Tasks</a></li>
        <li><a href="index.html#important-date">Important Dates</a></li>
        <li><a href="index.html#organizer">Organizers</a></li>
      </ul>
    </nav>
  </header>
</div>
<!-- ################################################################################################ -->
<div class="wrapper bgded overlay" style="background-image:url('images/demo/backgrounds/milky-way.jpeg');">
  <div id="pageintro" class="hoc clear">
      <h3 class="heading">The AAAI-2022 Workshop on <br>Video Transcript Understanding</h3>
      <h4>Feb 28, 2022</h4>
      <h4>Location: Online</h4>
  </div>
</div>
<!-- ################################################################################################ -->

<div class="wrapper row3"  style="background-color: whitesmoke;">
  <main class="hoc container clear">
    <!-- main body -->
    <section>
      <div>
        <h6 class="heading">Introduction</h6>

        <p>
          Due to the nature of speech, video transcripts pose many challenges to the existing
          natural language processing technologies such as the lack of organization such as clause, sentence, and paragraph;
          filler words, incomplete syntax, and incorrect grammar, and the existence of multiple speaker, sometimes speaking concomitantly.
         </p>
        <p>
          To push forware study on video transcript understanding, we propose the following shared tasks at VTU@AAAI-2022.
        </p>
      </div>
    </section>
  </main>
</div>

<div class="wrapper row3"  style="background-color: lightgray;">
  <main class="hoc container clear">
    <section>
      <div>
        <h6 class="heading">Task 1: Punctuation restoration (PR)</h6>
        <p>Punctuation restoration is a common post-processing problem for automatic speech recognition systems.
           It restores boundaries of sentences, clauses from ASR text. For instance:
        </p>

        <ul>
          <li><strong>INPUT:</strong>
            <p>bring it back right so most resourceful i'm not sure what's going to be there</p>
          </li>
          <li><strong>OUTPUT:</strong>
            <p>Bring it back.</p>
            <p>Right.</p>
            <p>So most resourceful, I'm not sure what's going to be there.</p>
          </li>
        </ul>
        <p>
          This task is modeled as a sequence labeling problem at token level.
          Participants will be provided human-annotated training and development datasets.
          The data, evaluation scripts, and testing will be done on our  <a href="https://github.com/vtuworkshop/shared_task_2022/tree/main/pr">github repo</a>.
        </p>
      </div>
    </section>
  </main>
</div>

<div class="wrapper row3"  style="background-color: whitesmoke;">
  <main class="hoc container clear">
    <section>
      <div>
        <h6 class="heading">Task 2: Domain Adaptation for Punctuation Restoration (DAPR)</h6>
        <p>This task is modeled similar to task 1. However, our focus shifts to exploiting existing transcripting text
           such as TED talk transcript and movie subtitle for punctuation restoration of live streaming video transcript.
           The data, evaluation scripts, and testing will be done on our  <a href="https://github.com/vtuworkshop/shared_task_2022/tree/main/dapr">github repo</a>.
        </p>
      </div>
    </section>
  </main>
</div>

<div class="wrapper row3"  style="background-color: lightgray;">
  <main class="hoc container clear">
    <section>
      <div>
        <h6 class="heading">Task 3: Chitchat detection (Chitchat)</h6>
        <p>One of the issues for the live-stream videos is that the streamer might get involved with off-topic discussions
           with the audience, hence diverging from the main topic and rendering the video uninformative.
           These off-topic sections, which we call them Chitchat, could introduce considerable challenges
           for the downstream applications on transcript processing.
        </p>

        <p>
          This task aims to detect chitchat sentences in the transcript. It is modeled as a sentiment analysis problem at sentence level.
          Participants will be provided human-annotated training and development datasets.
          The data, evaluation scripts, and testing will be done on our <a href="https://github.com/vtuworkshop/shared_task_2022/tree/main/chitchat">github repo</a>.
        </p>
      </div>
    </section>
  </main>
</div>

<div class="wrapper row3"  style="background-color: whitesmoke;">
  <main class="hoc container clear">
    <section>
      <div>
        <h6 class="heading">System paper</h6>
        <p>
          The participants of the both tasks are encouraged to submit their system papers to VTU@AAA-22 workshop.
          The system papers should provide details of the model architecture, the training method
          and all resources employed by the model in the training/evaluation phase,
          and the analysis of the strengths/weaknesses of the proposed model.
          Please use AAAI 2022 author kit to write the system papers following the AAAI 2022 formatting guidelines.
          System papers can be submitted as either short paper (4 pages) or long paper (8 pages).
          The papers will receive feedback from the workshop program committee and the accepted papers will be published
          in the workshop proceedings under the shared task section.
        </p>

        <p>Please submit the PDF formatted system papers to <a href="https://easychair.org/my/conference?conf=vtuaaai2022">EasyChair</a></p>
      </div>
    </section>
  </main>
</div>



<div class="wrapper row3"  style="background-color: midnightblue;">
  <main class="hoc container clear">
    <div class="clear">
      <p style="color: antiquewhite;">Contact us: vtu-2022@googlegroups.com</p>
    </div>
  </main>
</div>



<a id="backtotop" href="#top"><i class="fa fa-chevron-up"></i></a>
<!-- JAVASCRIPTS -->
<script src="layout/scripts/jquery.min.js"></script>
<script src="layout/scripts/jquery.backtotop.js"></script>
<script src="layout/scripts/jquery.mobilemenu.js"></script>
</body>
</html>